{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e669807e-c5cc-48b8-8e99-4ac9ea8c39f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### \uD83D\uDEE0️ Day 13 Tasks:\n",
    "\n",
    "1. Train 3 different models\n",
    "2. Compare metrics in MLflow\n",
    "3. Build Spark ML pipeline\n",
    "4. Select best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d02a8eba-61d6-4086-8da0-8cc65aea3675",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Task 1: Train 3 Different Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "207504da-c529-409b-a020-042d172383a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Load Data (Spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a5ec9a9-33b6-41cd-850b-1e27db16c260",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df = spark.table(\"ecommerce_catalog.gold.daily_sales_features\") \\\n",
    "          .select(\n",
    "              \"total_orders\",\n",
    "              \"is_weekend\",\n",
    "              \"avg_order_value\",\n",
    "              \"total_revenue\"\n",
    "          ) \\\n",
    "          .dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ac7e562-8e6c-4bba-a419-b4abb26edf8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Assemble Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6565e2c7-c047-48e0-9512-5a5abf7e50d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"total_orders\", \"is_weekend\", \"avg_order_value\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "data = assembler.transform(df).select(\"features\", \"total_revenue\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa23e76f-55fe-4c91-a11e-79f17adeda0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46e7b7df-869c-4ab8-8686-b968b920b65c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_df, test_df = data.randomSplit([0.8, 0.2], seed=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4a29b77-061d-41c0-97cb-cb379c2f7cde",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Define Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be2f51fc-ac5b-4c1c-8fa5-fa752ca2043f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import (\n",
    "    LinearRegression,\n",
    "    DecisionTreeRegressor,\n",
    "    RandomForestRegressor\n",
    ")\n",
    "\n",
    "lr = LinearRegression(labelCol=\"total_revenue\")\n",
    "dt = DecisionTreeRegressor(labelCol=\"total_revenue\")\n",
    "rf = RandomForestRegressor(labelCol=\"total_revenue\", numTrees=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b620a697-a324-4b03-ba5a-7ad7e74dd64b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aadaccb6-ab4d-49e4-a46b-8c50709c9830",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lr_model = lr.fit(train_df)\n",
    "dt_model = dt.fit(train_df)\n",
    "rf_model = rf.fit(train_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "487aa41f-c8df-449b-96a7-08c65a2db9b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Task 2: Compare Metrics in MLflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "780ff776-afe4-45c2-a80d-26b67512b71e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Create / Choose a UC Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b1be28e-9bbf-4709-b044-84d42b486f31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 26
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "CREATE VOLUME IF NOT EXISTS workspace.ecommerce.mlflow_tmp;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e6f9e04-c1d4-4f07-ac41-5b303141718e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Configure MLflow to use UC Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0302c407-0bff-45df-809d-ce50de86a624",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"MLFLOW_DFS_TMP\"] = \"/Volumes/workspace/ecommerce/mlflow_tmp\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b150812-23cb-4e51-bf4b-d2eed009fac4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "336332c5-eba8-4485-9beb-d6e9ca3510c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.spark\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b736fd60-a663-497b-a360-04db923d8d15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Set MLflow Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39a75dc4-e861-4677-beb5-5b82a6d858e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='dbfs:/databricks/mlflow-tracking/4152753210750153', creation_time=1768998744986, experiment_id='4152753210750153', last_update_time=1768999998338, lifecycle_stage='active', name='/Day13_Model_Comparison', tags={'mlflow.experiment.sourceName': '/Day13_Model_Comparison',\n",
       " 'mlflow.experimentKind': 'custom_model_development',\n",
       " 'mlflow.experimentType': 'MLFLOW_EXPERIMENT',\n",
       " 'mlflow.ownerEmail': 'karthika2738@gmail.com',\n",
       " 'mlflow.ownerId': '78119440703336'}>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"/Day13_Model_Comparison\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d1aa9d5-7963-4659-bef7-6ec9bfe3138a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Create Evaluator (RMSE & R²)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b145906-3923-4b3a-847e-b2b201ab2670",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"total_revenue\",\n",
    "    predictionCol=\"prediction\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00170e23-b30e-41e5-90be-ee873f4a0fdf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Prepare Models Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7fb05bb8-7050-4f06-b76b-6bc63379538e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"LinearRegression\": lr_model,\n",
    "    \"DecisionTree\": dt_model,\n",
    "    \"RandomForest\": rf_model\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1e870d7-bdbf-4b63-91c2-12f6433159db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Create Input Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e13842cd-f613-44f9-bb72-ff5a43e8e610",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "input_example = test_df.limit(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c236eb65-2304-44ad-b6a5-e6eaf573b2ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Log Each Model to MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b2b63ed-b3e4-4f12-9d53-7ebd1120865f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Log Each Model to MLflow"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"ts\": \"2026-01-21 17:09:13.489\", \"level\": \"ERROR\", \"logger\": \"pyspark.sql.connect.logging\", \"msg\": \"GRPC Error received\", \"context\": {}, \"exception\": {\"class\": \"_InactiveRpcError\", \"msg\": \"<_InactiveRpcError of RPC that terminated with:\\n\\tstatus = StatusCode.INTERNAL\\n\\tdetails = \\\"requirement failed: Column features must be of type class org.apache.spark.ml.linalg.VectorUDT:struct<type:tinyint,size:int,indices:array<int>,values:array<double>> but was actually class org.apache.spark.sql.types.ArrayType:array<double>.\\\"\\n\\tdebug_error_string = \\\"UNKNOWN:Error received from peer  {created_time:\\\"2026-01-21T17:09:13.488210602+00:00\\\", grpc_status:13, grpc_message:\\\"requirement failed: Column features must be of type class org.apache.spark.ml.linalg.VectorUDT:struct<type:tinyint,size:int,indices:array<int>,values:array<double>> but was actually class org.apache.spark.sql.types.ArrayType:array<double>.\\\"}\\\"\\n>\", \"stacktrace\": [{\"class\": null, \"method\": \"_analyze\", \"file\": \"/databricks/python/lib/python3.12/site-packages/pyspark/sql/connect/client/core.py\", \"line\": \"1811\"}, {\"class\": null, \"method\": \"__call__\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"277\"}, {\"class\": null, \"method\": \"_with_call\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"332\"}, {\"class\": null, \"method\": \"result\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_channel.py\", \"line\": \"440\"}, {\"class\": null, \"method\": \"continuation\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"315\"}, {\"class\": null, \"method\": \"with_call\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"343\"}, {\"class\": null, \"method\": \"_with_call\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"332\"}, {\"class\": null, \"method\": \"result\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_channel.py\", \"line\": \"440\"}, {\"class\": null, \"method\": \"continuation\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"315\"}, {\"class\": null, \"method\": \"with_call\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_channel.py\", \"line\": \"1198\"}, {\"class\": null, \"method\": \"_end_unary_response_blocking\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_channel.py\", \"line\": \"1006\"}]}}\n{\"ts\": \"2026-01-21 17:09:13.489\", \"level\": \"ERROR\", \"logger\": \"pyspark.sql.connect.logging\", \"msg\": \"GRPC Error received\", \"context\": {}, \"exception\": {\"class\": \"_InactiveRpcError\", \"msg\": \"<_InactiveRpcError of RPC that terminated with:\\n\\tstatus = StatusCode.INTERNAL\\n\\tdetails = \\\"requirement failed: Column features must be of type class org.apache.spark.ml.linalg.VectorUDT:struct<type:tinyint,size:int,indices:array<int>,values:array<double>> but was actually class org.apache.spark.sql.types.ArrayType:array<double>.\\\"\\n\\tdebug_error_string = \\\"UNKNOWN:Error received from peer  {created_time:\\\"2026-01-21T17:09:13.488210602+00:00\\\", grpc_status:13, grpc_message:\\\"requirement failed: Column features must be of type class org.apache.spark.ml.linalg.VectorUDT:struct<type:tinyint,size:int,indices:array<int>,values:array<double>> but was actually class org.apache.spark.sql.types.ArrayType:array<double>.\\\"}\\\"\\n>\", \"stacktrace\": [{\"class\": null, \"method\": \"_analyze\", \"file\": \"/databricks/python/lib/python3.12/site-packages/pyspark/sql/connect/client/core.py\", \"line\": \"1811\"}, {\"class\": null, \"method\": \"__call__\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"277\"}, {\"class\": null, \"method\": \"_with_call\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"332\"}, {\"class\": null, \"method\": \"result\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_channel.py\", \"line\": \"440\"}, {\"class\": null, \"method\": \"continuation\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"315\"}, {\"class\": null, \"method\": \"with_call\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"343\"}, {\"class\": null, \"method\": \"_with_call\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"332\"}, {\"class\": null, \"method\": \"result\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_channel.py\", \"line\": \"440\"}, {\"class\": null, \"method\": \"continuation\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"315\"}, {\"class\": null, \"method\": \"with_call\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_channel.py\", \"line\": \"1198\"}, {\"class\": null, \"method\": \"_end_unary_response_blocking\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_channel.py\", \"line\": \"1006\"}]}}\n{\"ts\": \"2026-01-21 17:09:13.489\", \"level\": \"ERROR\", \"logger\": \"pyspark.sql.connect.logging\", \"msg\": \"GRPC Error received\", \"context\": {}, \"exception\": {\"class\": \"_InactiveRpcError\", \"msg\": \"<_InactiveRpcError of RPC that terminated with:\\n\\tstatus = StatusCode.INTERNAL\\n\\tdetails = \\\"requirement failed: Column features must be of type class org.apache.spark.ml.linalg.VectorUDT:struct<type:tinyint,size:int,indices:array<int>,values:array<double>> but was actually class org.apache.spark.sql.types.ArrayType:array<double>.\\\"\\n\\tdebug_error_string = \\\"UNKNOWN:Error received from peer  {created_time:\\\"2026-01-21T17:09:13.488210602+00:00\\\", grpc_status:13, grpc_message:\\\"requirement failed: Column features must be of type class org.apache.spark.ml.linalg.VectorUDT:struct<type:tinyint,size:int,indices:array<int>,values:array<double>> but was actually class org.apache.spark.sql.types.ArrayType:array<double>.\\\"}\\\"\\n>\", \"stacktrace\": [{\"class\": null, \"method\": \"_analyze\", \"file\": \"/databricks/python/lib/python3.12/site-packages/pyspark/sql/connect/client/core.py\", \"line\": \"1811\"}, {\"class\": null, \"method\": \"__call__\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"277\"}, {\"class\": null, \"method\": \"_with_call\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"332\"}, {\"class\": null, \"method\": \"result\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_channel.py\", \"line\": \"440\"}, {\"class\": null, \"method\": \"continuation\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"315\"}, {\"class\": null, \"method\": \"with_call\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"343\"}, {\"class\": null, \"method\": \"_with_call\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"332\"}, {\"class\": null, \"method\": \"result\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_channel.py\", \"line\": \"440\"}, {\"class\": null, \"method\": \"continuation\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"315\"}, {\"class\": null, \"method\": \"with_call\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_channel.py\", \"line\": \"1198\"}, {\"class\": null, \"method\": \"_end_unary_response_blocking\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_channel.py\", \"line\": \"1006\"}]}}\n2026/01/21 17:09:13 WARNING mlflow.spark: Failed to infer the model signature from the input example. Reason: IllegalArgumentException('requirement failed: Column features must be of type class org.apache.spark.ml.linalg.VectorUDT:struct<type:tinyint,size:int,indices:array<int>,values:array<double>> but was actually class org.apache.spark.sql.types.ArrayType:array<double>.'). To see the full traceback, set the logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)`.\n2026/01/21 17:09:21 WARNING mlflow.utils.requirements_utils: Found pyspark version (4.0.0+databricks.connect.17.2.2) contains a local version label (+databricks.connect.17.2.2). MLflow logged a pip requirement for this package as 'pyspark==4.0.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n2026/01/21 17:09:25 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /local_disk0/user_tmp_data/spark-abb19d30-d846-495e-a1ec-44/tmpx3inyyl9/model, flavor: spark). Fall back to return ['pyspark==4.0.0']. Set logging level to DEBUG to see the full traceback. \n\u001B[31m2026/01/21 17:09:25 WARNING mlflow.models.model: Model logged without a signature. Signatures are required for Databricks UC model registry as they validate model inputs and denote the expected schema of model outputs. Please visit https://www.mlflow.org/docs/2.22.0/model/signatures.html#how-to-set-signatures-on-models for instructions on setting signature on models.\u001B[0m\n{\"ts\": \"2026-01-21 17:09:46.497\", \"level\": \"ERROR\", \"logger\": \"pyspark.sql.connect.logging\", \"msg\": \"GRPC Error received\", \"context\": {}, \"exception\": {\"class\": \"_InactiveRpcError\", \"msg\": \"<_InactiveRpcError of RPC that terminated with:\\n\\tstatus = StatusCode.INTERNAL\\n\\tdetails = \\\"requirement failed: Column features must be of type class org.apache.spark.ml.linalg.VectorUDT:struct<type:tinyint,size:int,indices:array<int>,values:array<double>> but was actually class org.apache.spark.sql.types.ArrayType:array<double>.\\\"\\n\\tdebug_error_string = \\\"UNKNOWN:Error received from peer  {created_time:\\\"2026-01-21T17:09:46.496950017+00:00\\\", grpc_status:13, grpc_message:\\\"requirement failed: Column features must be of type class org.apache.spark.ml.linalg.VectorUDT:struct<type:tinyint,size:int,indices:array<int>,values:array<double>> but was actually class org.apache.spark.sql.types.ArrayType:array<double>.\\\"}\\\"\\n>\", \"stacktrace\": [{\"class\": null, \"method\": \"_analyze\", \"file\": \"/databricks/python/lib/python3.12/site-packages/pyspark/sql/connect/client/core.py\", \"line\": \"1811\"}, {\"class\": null, \"method\": \"__call__\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"277\"}, {\"class\": null, \"method\": \"_with_call\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"332\"}, {\"class\": null, \"method\": \"result\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_channel.py\", \"line\": \"440\"}, {\"class\": null, \"method\": \"continuation\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"315\"}, {\"class\": null, \"method\": \"with_call\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"343\"}, {\"class\": null, \"method\": \"_with_call\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"332\"}, {\"class\": null, \"method\": \"result\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_channel.py\", \"line\": \"440\"}, {\"class\": null, \"method\": \"continuation\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"315\"}, {\"class\": null, \"method\": \"with_call\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_channel.py\", \"line\": \"1198\"}, {\"class\": null, \"method\": \"_end_unary_response_blocking\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_channel.py\", \"line\": \"1006\"}]}}\n{\"ts\": \"2026-01-21 17:09:46.497\", \"level\": \"ERROR\", \"logger\": \"pyspark.sql.connect.logging\", \"msg\": \"GRPC Error received\", \"context\": {}, \"exception\": {\"class\": \"_InactiveRpcError\", \"msg\": \"<_InactiveRpcError of RPC that terminated with:\\n\\tstatus = StatusCode.INTERNAL\\n\\tdetails = \\\"requirement failed: Column features must be of type class org.apache.spark.ml.linalg.VectorUDT:struct<type:tinyint,size:int,indices:array<int>,values:array<double>> but was actually class org.apache.spark.sql.types.ArrayType:array<double>.\\\"\\n\\tdebug_error_string = \\\"UNKNOWN:Error received from peer  {created_time:\\\"2026-01-21T17:09:46.496950017+00:00\\\", grpc_status:13, grpc_message:\\\"requirement failed: Column features must be of type class org.apache.spark.ml.linalg.VectorUDT:struct<type:tinyint,size:int,indices:array<int>,values:array<double>> but was actually class org.apache.spark.sql.types.ArrayType:array<double>.\\\"}\\\"\\n>\", \"stacktrace\": [{\"class\": null, \"method\": \"_analyze\", \"file\": \"/databricks/python/lib/python3.12/site-packages/pyspark/sql/connect/client/core.py\", \"line\": \"1811\"}, {\"class\": null, \"method\": \"__call__\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"277\"}, {\"class\": null, \"method\": \"_with_call\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"332\"}, {\"class\": null, \"method\": \"result\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_channel.py\", \"line\": \"440\"}, {\"class\": null, \"method\": \"continuation\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"315\"}, {\"class\": null, \"method\": \"with_call\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"343\"}, {\"class\": null, \"method\": \"_with_call\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"332\"}, {\"class\": null, \"method\": \"result\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_channel.py\", \"line\": \"440\"}, {\"class\": null, \"method\": \"continuation\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"315\"}, {\"class\": null, \"method\": \"with_call\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_channel.py\", \"line\": \"1198\"}, {\"class\": null, \"method\": \"_end_unary_response_blocking\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_channel.py\", \"line\": \"1006\"}]}}\n{\"ts\": \"2026-01-21 17:09:46.497\", \"level\": \"ERROR\", \"logger\": \"pyspark.sql.connect.logging\", \"msg\": \"GRPC Error received\", \"context\": {}, \"exception\": {\"class\": \"_InactiveRpcError\", \"msg\": \"<_InactiveRpcError of RPC that terminated with:\\n\\tstatus = StatusCode.INTERNAL\\n\\tdetails = \\\"requirement failed: Column features must be of type class org.apache.spark.ml.linalg.VectorUDT:struct<type:tinyint,size:int,indices:array<int>,values:array<double>> but was actually class org.apache.spark.sql.types.ArrayType:array<double>.\\\"\\n\\tdebug_error_string = \\\"UNKNOWN:Error received from peer  {created_time:\\\"2026-01-21T17:09:46.496950017+00:00\\\", grpc_status:13, grpc_message:\\\"requirement failed: Column features must be of type class org.apache.spark.ml.linalg.VectorUDT:struct<type:tinyint,size:int,indices:array<int>,values:array<double>> but was actually class org.apache.spark.sql.types.ArrayType:array<double>.\\\"}\\\"\\n>\", \"stacktrace\": [{\"class\": null, \"method\": \"_analyze\", \"file\": \"/databricks/python/lib/python3.12/site-packages/pyspark/sql/connect/client/core.py\", \"line\": \"1811\"}, {\"class\": null, \"method\": \"__call__\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"277\"}, {\"class\": null, \"method\": \"_with_call\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"332\"}, {\"class\": null, \"method\": \"result\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_channel.py\", \"line\": \"440\"}, {\"class\": null, \"method\": \"continuation\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"315\"}, {\"class\": null, \"method\": \"with_call\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"343\"}, {\"class\": null, \"method\": \"_with_call\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"332\"}, {\"class\": null, \"method\": \"result\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_channel.py\", \"line\": \"440\"}, {\"class\": null, \"method\": \"continuation\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"315\"}, {\"class\": null, \"method\": \"with_call\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_channel.py\", \"line\": \"1198\"}, {\"class\": null, \"method\": \"_end_unary_response_blocking\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_channel.py\", \"line\": \"1006\"}]}}\nERROR:pyspark.sql.connect.logging:GRPC Error received\nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.12/site-packages/pyspark/sql/connect/client/core.py\", line 1811, in _analyze\n    resp = self._stub.AnalyzePlan(req, metadata=self.metadata())\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", line 277, in __call__\n    response, ignored_call = self._with_call(\n                             ^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", line 332, in _with_call\n    return call.result(), call\n           ^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/grpc/_channel.py\", line 440, in result\n    raise self\n  File \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", line 315, in continuation\n    response, call = self._thunk(new_method).with_call(\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", line 343, in with_call\n    return self._with_call(\n           ^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", line 332, in _with_call\n    return call.result(), call\n           ^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/grpc/_channel.py\", line 440, in result\n    raise self\n  File \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", line 315, in continuation\n    response, call = self._thunk(new_method).with_call(\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/grpc/_channel.py\", line 1198, in with_call\n    return _end_unary_response_blocking(state, call, True, None)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/grpc/_channel.py\", line 1006, in _end_unary_response_blocking\n    raise _InactiveRpcError(state)  # pytype: disable=not-instantiable\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ngrpc._channel._InactiveRpcError: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.INTERNAL\n\tdetails = \"requirement failed: Column features must be of type class org.apache.spark.ml.linalg.VectorUDT:struct<type:tinyint,size:int,indices:array<int>,values:array<double>> but was actually class org.apache.spark.sql.types.ArrayType:array<double>.\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {created_time:\"2026-01-21T17:09:46.496950017+00:00\", grpc_status:13, grpc_message:\"requirement failed: Column features must be of type class org.apache.spark.ml.linalg.VectorUDT:struct<type:tinyint,size:int,indices:array<int>,values:array<double>> but was actually class org.apache.spark.sql.types.ArrayType:array<double>.\"}\"\n>\n2026/01/21 17:09:46 WARNING mlflow.spark: Failed to infer the model signature from the input example. Reason: IllegalArgumentException('requirement failed: Column features must be of type class org.apache.spark.ml.linalg.VectorUDT:struct<type:tinyint,size:int,indices:array<int>,values:array<double>> but was actually class org.apache.spark.sql.types.ArrayType:array<double>.'). To see the full traceback, set the logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)`.\n2026/01/21 17:09:52 WARNING mlflow.utils.requirements_utils: Found pyspark version (4.0.0+databricks.connect.17.2.2) contains a local version label (+databricks.connect.17.2.2). MLflow logged a pip requirement for this package as 'pyspark==4.0.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n2026/01/21 17:09:54 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /local_disk0/user_tmp_data/spark-abb19d30-d846-495e-a1ec-44/tmpe0obwzqg/model, flavor: spark). Fall back to return ['pyspark==4.0.0']. Set logging level to DEBUG to see the full traceback. \n\u001B[31m2026/01/21 17:09:55 WARNING mlflow.models.model: Model logged without a signature. Signatures are required for Databricks UC model registry as they validate model inputs and denote the expected schema of model outputs. Please visit https://www.mlflow.org/docs/2.22.0/model/signatures.html#how-to-set-signatures-on-models for instructions on setting signature on models.\u001B[0m\n{\"ts\": \"2026-01-21 17:10:07.158\", \"level\": \"ERROR\", \"logger\": \"pyspark.sql.connect.logging\", \"msg\": \"GRPC Error received\", \"context\": {}, \"exception\": {\"class\": \"_InactiveRpcError\", \"msg\": \"<_InactiveRpcError of RPC that terminated with:\\n\\tstatus = StatusCode.INTERNAL\\n\\tdetails = \\\"requirement failed: Column features must be of type class org.apache.spark.ml.linalg.VectorUDT:struct<type:tinyint,size:int,indices:array<int>,values:array<double>> but was actually class org.apache.spark.sql.types.ArrayType:array<double>.\\\"\\n\\tdebug_error_string = \\\"UNKNOWN:Error received from peer  {created_time:\\\"2026-01-21T17:10:07.15794186+00:00\\\", grpc_status:13, grpc_message:\\\"requirement failed: Column features must be of type class org.apache.spark.ml.linalg.VectorUDT:struct<type:tinyint,size:int,indices:array<int>,values:array<double>> but was actually class org.apache.spark.sql.types.ArrayType:array<double>.\\\"}\\\"\\n>\", \"stacktrace\": [{\"class\": null, \"method\": \"_analyze\", \"file\": \"/databricks/python/lib/python3.12/site-packages/pyspark/sql/connect/client/core.py\", \"line\": \"1811\"}, {\"class\": null, \"method\": \"__call__\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"277\"}, {\"class\": null, \"method\": \"_with_call\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"332\"}, {\"class\": null, \"method\": \"result\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_channel.py\", \"line\": \"440\"}, {\"class\": null, \"method\": \"continuation\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"315\"}, {\"class\": null, \"method\": \"with_call\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"343\"}, {\"class\": null, \"method\": \"_with_call\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"332\"}, {\"class\": null, \"method\": \"result\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_channel.py\", \"line\": \"440\"}, {\"class\": null, \"method\": \"continuation\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"315\"}, {\"class\": null, \"method\": \"with_call\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_channel.py\", \"line\": \"1198\"}, {\"class\": null, \"method\": \"_end_unary_response_blocking\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_channel.py\", \"line\": \"1006\"}]}}\n{\"ts\": \"2026-01-21 17:10:07.158\", \"level\": \"ERROR\", \"logger\": \"pyspark.sql.connect.logging\", \"msg\": \"GRPC Error received\", \"context\": {}, \"exception\": {\"class\": \"_InactiveRpcError\", \"msg\": \"<_InactiveRpcError of RPC that terminated with:\\n\\tstatus = StatusCode.INTERNAL\\n\\tdetails = \\\"requirement failed: Column features must be of type class org.apache.spark.ml.linalg.VectorUDT:struct<type:tinyint,size:int,indices:array<int>,values:array<double>> but was actually class org.apache.spark.sql.types.ArrayType:array<double>.\\\"\\n\\tdebug_error_string = \\\"UNKNOWN:Error received from peer  {created_time:\\\"2026-01-21T17:10:07.15794186+00:00\\\", grpc_status:13, grpc_message:\\\"requirement failed: Column features must be of type class org.apache.spark.ml.linalg.VectorUDT:struct<type:tinyint,size:int,indices:array<int>,values:array<double>> but was actually class org.apache.spark.sql.types.ArrayType:array<double>.\\\"}\\\"\\n>\", \"stacktrace\": [{\"class\": null, \"method\": \"_analyze\", \"file\": \"/databricks/python/lib/python3.12/site-packages/pyspark/sql/connect/client/core.py\", \"line\": \"1811\"}, {\"class\": null, \"method\": \"__call__\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"277\"}, {\"class\": null, \"method\": \"_with_call\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"332\"}, {\"class\": null, \"method\": \"result\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_channel.py\", \"line\": \"440\"}, {\"class\": null, \"method\": \"continuation\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"315\"}, {\"class\": null, \"method\": \"with_call\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"343\"}, {\"class\": null, \"method\": \"_with_call\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"332\"}, {\"class\": null, \"method\": \"result\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_channel.py\", \"line\": \"440\"}, {\"class\": null, \"method\": \"continuation\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"315\"}, {\"class\": null, \"method\": \"with_call\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_channel.py\", \"line\": \"1198\"}, {\"class\": null, \"method\": \"_end_unary_response_blocking\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_channel.py\", \"line\": \"1006\"}]}}\n{\"ts\": \"2026-01-21 17:10:07.158\", \"level\": \"ERROR\", \"logger\": \"pyspark.sql.connect.logging\", \"msg\": \"GRPC Error received\", \"context\": {}, \"exception\": {\"class\": \"_InactiveRpcError\", \"msg\": \"<_InactiveRpcError of RPC that terminated with:\\n\\tstatus = StatusCode.INTERNAL\\n\\tdetails = \\\"requirement failed: Column features must be of type class org.apache.spark.ml.linalg.VectorUDT:struct<type:tinyint,size:int,indices:array<int>,values:array<double>> but was actually class org.apache.spark.sql.types.ArrayType:array<double>.\\\"\\n\\tdebug_error_string = \\\"UNKNOWN:Error received from peer  {created_time:\\\"2026-01-21T17:10:07.15794186+00:00\\\", grpc_status:13, grpc_message:\\\"requirement failed: Column features must be of type class org.apache.spark.ml.linalg.VectorUDT:struct<type:tinyint,size:int,indices:array<int>,values:array<double>> but was actually class org.apache.spark.sql.types.ArrayType:array<double>.\\\"}\\\"\\n>\", \"stacktrace\": [{\"class\": null, \"method\": \"_analyze\", \"file\": \"/databricks/python/lib/python3.12/site-packages/pyspark/sql/connect/client/core.py\", \"line\": \"1811\"}, {\"class\": null, \"method\": \"__call__\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"277\"}, {\"class\": null, \"method\": \"_with_call\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"332\"}, {\"class\": null, \"method\": \"result\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_channel.py\", \"line\": \"440\"}, {\"class\": null, \"method\": \"continuation\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"315\"}, {\"class\": null, \"method\": \"with_call\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"343\"}, {\"class\": null, \"method\": \"_with_call\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"332\"}, {\"class\": null, \"method\": \"result\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_channel.py\", \"line\": \"440\"}, {\"class\": null, \"method\": \"continuation\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", \"line\": \"315\"}, {\"class\": null, \"method\": \"with_call\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_channel.py\", \"line\": \"1198\"}, {\"class\": null, \"method\": \"_end_unary_response_blocking\", \"file\": \"/databricks/python/lib/python3.12/site-packages/grpc/_channel.py\", \"line\": \"1006\"}]}}\nERROR:pyspark.sql.connect.logging:GRPC Error received\nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.12/site-packages/pyspark/sql/connect/client/core.py\", line 1811, in _analyze\n    resp = self._stub.AnalyzePlan(req, metadata=self.metadata())\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", line 277, in __call__\n    response, ignored_call = self._with_call(\n                             ^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", line 332, in _with_call\n    return call.result(), call\n           ^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/grpc/_channel.py\", line 440, in result\n    raise self\n  File \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", line 315, in continuation\n    response, call = self._thunk(new_method).with_call(\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", line 343, in with_call\n    return self._with_call(\n           ^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", line 332, in _with_call\n    return call.result(), call\n           ^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/grpc/_channel.py\", line 440, in result\n    raise self\n  File \"/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py\", line 315, in continuation\n    response, call = self._thunk(new_method).with_call(\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/grpc/_channel.py\", line 1198, in with_call\n    return _end_unary_response_blocking(state, call, True, None)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/grpc/_channel.py\", line 1006, in _end_unary_response_blocking\n    raise _InactiveRpcError(state)  # pytype: disable=not-instantiable\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ngrpc._channel._InactiveRpcError: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.INTERNAL\n\tdetails = \"requirement failed: Column features must be of type class org.apache.spark.ml.linalg.VectorUDT:struct<type:tinyint,size:int,indices:array<int>,values:array<double>> but was actually class org.apache.spark.sql.types.ArrayType:array<double>.\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {created_time:\"2026-01-21T17:10:07.15794186+00:00\", grpc_status:13, grpc_message:\"requirement failed: Column features must be of type class org.apache.spark.ml.linalg.VectorUDT:struct<type:tinyint,size:int,indices:array<int>,values:array<double>> but was actually class org.apache.spark.sql.types.ArrayType:array<double>.\"}\"\n>\n2026/01/21 17:10:07 WARNING mlflow.spark: Failed to infer the model signature from the input example. Reason: IllegalArgumentException('requirement failed: Column features must be of type class org.apache.spark.ml.linalg.VectorUDT:struct<type:tinyint,size:int,indices:array<int>,values:array<double>> but was actually class org.apache.spark.sql.types.ArrayType:array<double>.'). To see the full traceback, set the logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)`.\n2026/01/21 17:10:13 WARNING mlflow.utils.requirements_utils: Found pyspark version (4.0.0+databricks.connect.17.2.2) contains a local version label (+databricks.connect.17.2.2). MLflow logged a pip requirement for this package as 'pyspark==4.0.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n2026/01/21 17:10:16 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /local_disk0/user_tmp_data/spark-abb19d30-d846-495e-a1ec-44/tmp_qd54ebt/model, flavor: spark). Fall back to return ['pyspark==4.0.0']. Set logging level to DEBUG to see the full traceback. \n\u001B[31m2026/01/21 17:10:16 WARNING mlflow.models.model: Model logged without a signature. Signatures are required for Databricks UC model registry as they validate model inputs and denote the expected schema of model outputs. Please visit https://www.mlflow.org/docs/2.22.0/model/signatures.html#how-to-set-signatures-on-models for instructions on setting signature on models.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "input_example_pd = input_example.toPandas()\n",
    "if 'features' in input_example_pd.columns:\n",
    "    input_example_pd['features'] = input_example_pd['features'].apply(lambda x: x.toArray().tolist() if hasattr(x, 'toArray') else list(x) if hasattr(x, '__iter__') else x)\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    # 1. Generate predictions\n",
    "    predictions = model.transform(test_df)\n",
    "\n",
    "    # 2. Calculate RMSE\n",
    "    evaluator.setMetricName(\"rmse\")\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "    # 3. Calculate R2\n",
    "    evaluator.setMetricName(\"r2\")\n",
    "    r2 = evaluator.evaluate(predictions)\n",
    "\n",
    "    # 4. Start MLflow run\n",
    "    with mlflow.start_run():\n",
    "        # Log parameters\n",
    "        mlflow.log_param(\"model_type\", model_name)\n",
    "        # Log metrics\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.log_metric(\"r2_score\", r2)\n",
    "        # Log Spark ML model WITH input example\n",
    "        mlflow.spark.log_model(\n",
    "            model,\n",
    "            artifact_path=\"model\",\n",
    "            input_example=input_example_pd\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38160425-42ea-4a36-81d0-d428b723a86a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Verify in MLflow UI\n",
    "\n",
    "1.Click \uD83E\uDDEA Experiments icon (right sidebar)\n",
    "\n",
    "2.Open experiment:\n",
    "\n",
    "Day13_Model_Comparison\n",
    "\n",
    "\n",
    "3.You should see 3 runs:\n",
    "\n",
    "LinearRegression\n",
    "\n",
    "DecisionTree\n",
    "\n",
    "RandomForest\n",
    "\n",
    "Each run will show:\n",
    "\n",
    "Parameters ✔\n",
    "\n",
    "RMSE ✔\n",
    "\n",
    "R² ✔\n",
    "\n",
    "Spark model artifact ✔"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "213abb37-285d-4f65-8b0f-84e065ac3513",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Task 3: Build Spark ML Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d45a0a5b-4d58-4077-a033-c32cac87ead4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Import Required Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7518ca5d-9992-4c22-b520-c63eaed2f787",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c98d10d-0927-40f4-b9f9-39d094e2d099",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Define Feature Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3aab4a79-1e23-4979-8136-6bf57b7c2885",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "feature_cols = [\"total_orders\", \"is_weekend\", \"avg_order_value\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d982e4d3-0c71-4892-af3b-97e45f8a4db5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Create VectorAssembler (Feature Stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e140f81a-ccc3-421f-9ff9-7e881206a804",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create VectorAssembler (Feature Stage)"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=feature_cols,\n",
    "    outputCol=\"features\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "910040a5-d5d0-451e-a69e-a8673a6099af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Define the Model Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "977eb584-1759-4559-8cd8-66504222e70f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"total_revenue\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "199ff1fd-3dfa-4eec-91fc-3573afebcc34",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Create the Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb4ba991-9ee9-4a0b-89f1-bf58ed57508d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[\n",
    "    assembler,\n",
    "    lr\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84f56d36-a939-4915-aaff-b8da340c3e25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Train the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4489bed3-24f2-458e-b6b4-6b7999e4f64e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Train the Pipeline"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:py4j.clientserver:Received command c on object id p0\n"
     ]
    }
   ],
   "source": [
    "df = spark.table(\"ecommerce_catalog.gold.daily_sales_features\").dropna()\n",
    "pipeline_model = pipeline.fit(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2da43c3-7030-4ba8-a90e-8b12e32db18b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Generate Predictions Using Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6916ee7-f196-4efc-bf5c-5d9771720887",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>total_orders</th><th>is_weekend</th><th>avg_order_value</th><th>total_revenue</th><th>prediction</th></tr></thead><tbody><tr><td>1189507</td><td>0</td><td>300.6065023828165</td><td>3.5757353882987684E8</td><td>3.630732527025794E8</td></tr><tr><td>1125950</td><td>0</td><td>301.5065523779545</td><td>3.394813026499579E8</td><td>3.456604279444033E8</td></tr><tr><td>1415671</td><td>0</td><td>299.2876306855224</td><td>4.236928194202042E8</td><td>4.288331528777374E8</td></tr><tr><td>1329047</td><td>1</td><td>297.7144504971646</td><td>3.956764972899051E8</td><td>3.971234223814404E8</td></tr><tr><td>1317309</td><td>1</td><td>301.39099258424864</td><td>3.97025067050164E8</td><td>4.0098320702472806E8</td></tr><tr><td>1198695</td><td>0</td><td>296.5300084675094</td><td>3.554490384999612E8</td><td>3.5763587743608296E8</td></tr><tr><td>1365036</td><td>0</td><td>279.01953442247566</td><td>3.808717091899185E8</td><td>3.726612945832708E8</td></tr><tr><td>1342556</td><td>0</td><td>282.8748700390103</td><td>3.7977535402009356E8</td><td>3.736318380694982E8</td></tr><tr><td>1281337</td><td>0</td><td>290.3646107934492</td><td>3.7205491930024576E8</td><td>3.7020898630504465E8</td></tr><tr><td>1492836</td><td>0</td><td>282.5372595984001</td><td>4.217817924698372E8</td><td>4.1841348947436976E8</td></tr><tr><td>1478385</td><td>1</td><td>282.2026435332283</td><td>4.1720415515987176E8</td><td>4.110338208575522E8</td></tr><tr><td>1637966</td><td>1</td><td>279.7481167007255</td><td>4.582179037198206E8</td><td>4.5436215715177476E8</td></tr><tr><td>1449500</td><td>0</td><td>299.0999073056632</td><td>4.335453156395588E8</td><td>4.3868859054100716E8</td></tr><tr><td>1538294</td><td>0</td><td>296.8004665492867</td><td>4.565663768899684E8</td><td>4.6091530166965306E8</td></tr><tr><td>1519989</td><td>0</td><td>291.5064620401441</td><td>4.4308661572993654E8</td><td>4.447067345417572E8</td></tr><tr><td>1405860</td><td>0</td><td>292.3776401844541</td><td>4.1104202922971666E8</td><td>4.1193685390480125E8</td></tr><tr><td>1479382</td><td>0</td><td>288.16669881076007</td><td>4.263086272200598E8</td><td>4.2569056624547505E8</td></tr><tr><td>1446515</td><td>1</td><td>289.70618418041556</td><td>4.1906434100973386E8</td><td>4.1651733914242566E8</td></tr><tr><td>1509469</td><td>1</td><td>289.15506963033295</td><td>4.3647061379982907E8</td><td>4.344510877421745E8</td></tr><tr><td>1404510</td><td>0</td><td>286.23474767742255</td><td>4.0201956546041673E8</td><td>3.991463681828201E8</td></tr><tr><td>1415383</td><td>0</td><td>287.65384340476396</td><td>4.07140359839765E8</td><td>4.052960679861375E8</td></tr><tr><td>1379533</td><td>0</td><td>287.28075933666156</td><td>3.963132877699827E8</td><td>3.936988378663167E8</td></tr><tr><td>1312467</td><td>0</td><td>292.1835162027448</td><td>3.834812229600678E8</td><td>3.8329264816334164E8</td></tr><tr><td>1430651</td><td>0</td><td>287.9425633016182</td><td>4.1194531613002336E8</td><td>4.1049685455442405E8</td></tr><tr><td>1346368</td><td>1</td><td>289.73808174288087</td><td>3.9009408163999903E8</td><td>3.862855240942496E8</td></tr><tr><td>1387868</td><td>1</td><td>293.2669432540671</td><td>4.0701580600013554E8</td><td>4.0595300064027965E8</td></tr><tr><td>1259660</td><td>0</td><td>288.80498132827563</td><td>3.6379608277997565E8</td><td>3.6050762862479496E8</td></tr><tr><td>1225712</td><td>0</td><td>288.03385814951287</td><td>3.530465563401557E8</td><td>3.486834663303863E8</td></tr><tr><td>1207768</td><td>0</td><td>289.4447360087636</td><td>3.495820899198324E8</td><td>3.460989863709407E8</td></tr><tr><td>1244751</td><td>0</td><td>292.366045747155</td><td>3.6392292780981696E8</td><td>3.6317536804646146E8</td></tr><tr><td>1444123</td><td>0</td><td>294.78065736765615</td><td>4.256995272597517E8</td><td>4.2835574607244647E8</td></tr><tr><td>1554614</td><td>1</td><td>292.5806894767574</td><td>4.548500359902197E8</td><td>4.5501313470487297E8</td></tr><tr><td>1567159</td><td>1</td><td>298.0518274790894</td><td>4.670946039003023E8</td><td>4.698362512995194E8</td></tr><tr><td>1792153</td><td>0</td><td>296.7259841096903</td><td>5.317783626001338E8</td><td>5.375616807305001E8</td></tr><tr><td>1714743</td><td>0</td><td>288.84073929440837</td><td>4.952876358199117E8</td><td>4.982497774941031E8</td></tr><tr><td>1689348</td><td>0</td><td>289.8600666885924</td><td>4.8967452394024014E8</td><td>4.926220084554528E8</td></tr><tr><td>1793121</td><td>0</td><td>285.9023411245707</td><td>5.126574918196313E8</td><td>5.160375458544165E8</td></tr><tr><td>1892841</td><td>0</td><td>293.05358298973846</td><td>5.547038370798795E8</td><td>5.606190770115899E8</td></tr><tr><td>1876003</td><td>1</td><td>291.23653800650385</td><td>5.463606190098152E8</td><td>5.495292035189401E8</td></tr><tr><td>1940015</td><td>1</td><td>294.11272867495774</td><td>5.705831053203481E8</td><td>5.746913555764538E8</td></tr><tr><td>2007483</td><td>0</td><td>288.8054086087422</td><td>5.797719480901036E8</td><td>5.867372141297075E8</td></tr><tr><td>1985147</td><td>0</td><td>293.92283101448567</td><td>5.834800262199131E8</td><td>5.902952795863937E8</td></tr><tr><td>2014572</td><td>0</td><td>299.15987626659796</td><td>6.026791102501528E8</td><td>6.097530176410304E8</td></tr><tr><td>3056717</td><td>0</td><td>325.14729260566673</td><td>9.938832568117157E8</td><td>9.774012182168862E8</td></tr><tr><td>6173628</td><td>0</td><td>307.44125973767103</td><td>1.8980279694717586E9</td><td>1.8846282759042134E9</td></tr><tr><td>6460123</td><td>1</td><td>309.35040353578796</td><td>1.998441656940825E9</td><td>1.972812404462103E9</td></tr><tr><td>6371159</td><td>1</td><td>294.5273366272873</td><td>1.8764804914989712E9</td><td>1.916020816655179E9</td></tr><tr><td>2017005</td><td>0</td><td>290.09585731811507</td><td>5.851247946899247E8</td><td>5.92218903406856E8</td></tr><tr><td>1725089</td><td>0</td><td>283.9914724166876</td><td>4.8991056515983117E8</td><td>4.9160505535518086E8</td></tr><tr><td>1695812</td><td>0</td><td>275.27931951177726</td><td>4.6682197337990606E8</td><td>4.65187394346655E8</td></tr><tr><td>1673897</td><td>0</td><td>267.85653770799865</td><td>4.483642548998058E8</td><td>4.435958150738077E8</td></tr><tr><td>1565600</td><td>0</td><td>279.72321694544524</td><td>4.3793466844978905E8</td><td>4.3475359133101165E8</td></tr><tr><td>1561182</td><td>1</td><td>281.96560641871383</td><td>4.4019962935998046E8</td><td>4.356034811840621E8</td></tr><tr><td>1591284</td><td>1</td><td>281.0767669063965</td><td>4.472729619498782E8</td><td>4.4291821638571835E8</td></tr><tr><td>1592360</td><td>0</td><td>276.3213423848408</td><td>4.400030527599251E8</td><td>4.35991849177757E8</td></tr><tr><td>1653100</td><td>0</td><td>275.4269571532313</td><td>4.553083028700066E8</td><td>4.525639035627916E8</td></tr><tr><td>1642966</td><td>0</td><td>277.7606414558683</td><td>4.5635129005018216E8</td><td>4.542021566522707E8</td></tr><tr><td>1656000</td><td>0</td><td>284.96865065213234</td><td>4.719080854799311E8</td><td>4.7267417549218166E8</td></tr><tr><td>1852304</td><td>0</td><td>285.76721011749464</td><td>5.293277463694758E8</td><td>5.336689936547924E8</td></tr><tr><td>1754343</td><td>1</td><td>280.2194996418532</td><td>4.916011176601876E8</td><td>4.9051826447851145E8</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1189507,
         0,
         300.6065023828165,
         3.5757353882987684E8,
         3.630732527025794E8
        ],
        [
         1125950,
         0,
         301.5065523779545,
         3.394813026499579E8,
         3.456604279444033E8
        ],
        [
         1415671,
         0,
         299.2876306855224,
         4.236928194202042E8,
         4.288331528777374E8
        ],
        [
         1329047,
         1,
         297.7144504971646,
         3.956764972899051E8,
         3.971234223814404E8
        ],
        [
         1317309,
         1,
         301.39099258424864,
         3.97025067050164E8,
         4.0098320702472806E8
        ],
        [
         1198695,
         0,
         296.5300084675094,
         3.554490384999612E8,
         3.5763587743608296E8
        ],
        [
         1365036,
         0,
         279.01953442247566,
         3.808717091899185E8,
         3.726612945832708E8
        ],
        [
         1342556,
         0,
         282.8748700390103,
         3.7977535402009356E8,
         3.736318380694982E8
        ],
        [
         1281337,
         0,
         290.3646107934492,
         3.7205491930024576E8,
         3.7020898630504465E8
        ],
        [
         1492836,
         0,
         282.5372595984001,
         4.217817924698372E8,
         4.1841348947436976E8
        ],
        [
         1478385,
         1,
         282.2026435332283,
         4.1720415515987176E8,
         4.110338208575522E8
        ],
        [
         1637966,
         1,
         279.7481167007255,
         4.582179037198206E8,
         4.5436215715177476E8
        ],
        [
         1449500,
         0,
         299.0999073056632,
         4.335453156395588E8,
         4.3868859054100716E8
        ],
        [
         1538294,
         0,
         296.8004665492867,
         4.565663768899684E8,
         4.6091530166965306E8
        ],
        [
         1519989,
         0,
         291.5064620401441,
         4.4308661572993654E8,
         4.447067345417572E8
        ],
        [
         1405860,
         0,
         292.3776401844541,
         4.1104202922971666E8,
         4.1193685390480125E8
        ],
        [
         1479382,
         0,
         288.16669881076007,
         4.263086272200598E8,
         4.2569056624547505E8
        ],
        [
         1446515,
         1,
         289.70618418041556,
         4.1906434100973386E8,
         4.1651733914242566E8
        ],
        [
         1509469,
         1,
         289.15506963033295,
         4.3647061379982907E8,
         4.344510877421745E8
        ],
        [
         1404510,
         0,
         286.23474767742255,
         4.0201956546041673E8,
         3.991463681828201E8
        ],
        [
         1415383,
         0,
         287.65384340476396,
         4.07140359839765E8,
         4.052960679861375E8
        ],
        [
         1379533,
         0,
         287.28075933666156,
         3.963132877699827E8,
         3.936988378663167E8
        ],
        [
         1312467,
         0,
         292.1835162027448,
         3.834812229600678E8,
         3.8329264816334164E8
        ],
        [
         1430651,
         0,
         287.9425633016182,
         4.1194531613002336E8,
         4.1049685455442405E8
        ],
        [
         1346368,
         1,
         289.73808174288087,
         3.9009408163999903E8,
         3.862855240942496E8
        ],
        [
         1387868,
         1,
         293.2669432540671,
         4.0701580600013554E8,
         4.0595300064027965E8
        ],
        [
         1259660,
         0,
         288.80498132827563,
         3.6379608277997565E8,
         3.6050762862479496E8
        ],
        [
         1225712,
         0,
         288.03385814951287,
         3.530465563401557E8,
         3.486834663303863E8
        ],
        [
         1207768,
         0,
         289.4447360087636,
         3.495820899198324E8,
         3.460989863709407E8
        ],
        [
         1244751,
         0,
         292.366045747155,
         3.6392292780981696E8,
         3.6317536804646146E8
        ],
        [
         1444123,
         0,
         294.78065736765615,
         4.256995272597517E8,
         4.2835574607244647E8
        ],
        [
         1554614,
         1,
         292.5806894767574,
         4.548500359902197E8,
         4.5501313470487297E8
        ],
        [
         1567159,
         1,
         298.0518274790894,
         4.670946039003023E8,
         4.698362512995194E8
        ],
        [
         1792153,
         0,
         296.7259841096903,
         5.317783626001338E8,
         5.375616807305001E8
        ],
        [
         1714743,
         0,
         288.84073929440837,
         4.952876358199117E8,
         4.982497774941031E8
        ],
        [
         1689348,
         0,
         289.8600666885924,
         4.8967452394024014E8,
         4.926220084554528E8
        ],
        [
         1793121,
         0,
         285.9023411245707,
         5.126574918196313E8,
         5.160375458544165E8
        ],
        [
         1892841,
         0,
         293.05358298973846,
         5.547038370798795E8,
         5.606190770115899E8
        ],
        [
         1876003,
         1,
         291.23653800650385,
         5.463606190098152E8,
         5.495292035189401E8
        ],
        [
         1940015,
         1,
         294.11272867495774,
         5.705831053203481E8,
         5.746913555764538E8
        ],
        [
         2007483,
         0,
         288.8054086087422,
         5.797719480901036E8,
         5.867372141297075E8
        ],
        [
         1985147,
         0,
         293.92283101448567,
         5.834800262199131E8,
         5.902952795863937E8
        ],
        [
         2014572,
         0,
         299.15987626659796,
         6.026791102501528E8,
         6.097530176410304E8
        ],
        [
         3056717,
         0,
         325.14729260566673,
         9.938832568117157E8,
         9.774012182168862E8
        ],
        [
         6173628,
         0,
         307.44125973767103,
         1.8980279694717586E9,
         1.8846282759042134E9
        ],
        [
         6460123,
         1,
         309.35040353578796,
         1.998441656940825E9,
         1.972812404462103E9
        ],
        [
         6371159,
         1,
         294.5273366272873,
         1.8764804914989712E9,
         1.916020816655179E9
        ],
        [
         2017005,
         0,
         290.09585731811507,
         5.851247946899247E8,
         5.92218903406856E8
        ],
        [
         1725089,
         0,
         283.9914724166876,
         4.8991056515983117E8,
         4.9160505535518086E8
        ],
        [
         1695812,
         0,
         275.27931951177726,
         4.6682197337990606E8,
         4.65187394346655E8
        ],
        [
         1673897,
         0,
         267.85653770799865,
         4.483642548998058E8,
         4.435958150738077E8
        ],
        [
         1565600,
         0,
         279.72321694544524,
         4.3793466844978905E8,
         4.3475359133101165E8
        ],
        [
         1561182,
         1,
         281.96560641871383,
         4.4019962935998046E8,
         4.356034811840621E8
        ],
        [
         1591284,
         1,
         281.0767669063965,
         4.472729619498782E8,
         4.4291821638571835E8
        ],
        [
         1592360,
         0,
         276.3213423848408,
         4.400030527599251E8,
         4.35991849177757E8
        ],
        [
         1653100,
         0,
         275.4269571532313,
         4.553083028700066E8,
         4.525639035627916E8
        ],
        [
         1642966,
         0,
         277.7606414558683,
         4.5635129005018216E8,
         4.542021566522707E8
        ],
        [
         1656000,
         0,
         284.96865065213234,
         4.719080854799311E8,
         4.7267417549218166E8
        ],
        [
         1852304,
         0,
         285.76721011749464,
         5.293277463694758E8,
         5.336689936547924E8
        ],
        [
         1754343,
         1,
         280.2194996418532,
         4.916011176601876E8,
         4.9051826447851145E8
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "total_orders",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "is_weekend",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "avg_order_value",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "total_revenue",
         "type": "\"double\""
        },
        {
         "metadata": "{\"ml_attr\": {}}",
         "name": "prediction",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline_predictions = pipeline_model.transform(df)\n",
    "pipeline_predictions.select(\n",
    "    \"total_orders\",\n",
    "    \"is_weekend\",\n",
    "    \"avg_order_value\",\n",
    "    \"total_revenue\",\n",
    "    \"prediction\"\n",
    ").display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aedd97d7-ad28-4711-a179-b83c45c364dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Task 4 : Select best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "656fb8ff-9811-4190-b65a-844877cb239b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Selected Linear Regression as the final model based on lowest RMSE and highest R².\n",
    "The strong linear correlation between total orders and revenue made simpler models\n",
    "more effective than tree-based approaches for this dataset.\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6594116794260034,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Day 13",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}